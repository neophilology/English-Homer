{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normilizer for Peter Green's translation of the Odyssey\n",
    "\n",
    "Solid and clean copy. Here are some characteristics. \n",
    "\n",
    "## Before\n",
    "- Clean from origin\n",
    "    * no pagination or other in page marginalia\n",
    "    * no weid characters in text\n",
    "    * native digital version (no scan, OCR, etc)\n",
    "- Separated by books\n",
    "- Line number every five lines\n",
    "- Prosody \"diacritics\":  \n",
    "    - [] Macron (¯) in long vowels (Ancient Greek quirk)\n",
    "    - [] Dieresis (¨) in accented/pronounced vowels (Ancient Greek quirk)\n",
    "    - [] Diacritics, grace and acute (`|´)\n",
    "    - [] Circumflex (^) in vowels with high and falling pitch (Ancient Greek quirk) \n",
    "- Superscripts for footnotes remain\n",
    "- In `Cleaning`, it was stripped from source indicatorat the end of each book, i.e., footer line: EBSCOhost: eBook Collection (EBSCOhost) printed on 3/7/2025 11:00:14 PM UTC via UNIVERSITAET TUEBINGEN. All use subject to https://www.ebsco.com/terms-of-use.\n",
    "\n",
    "## After\n",
    "- clean text: only alphabetic characters\n",
    "- kept syntactical punctuation (. , ; : - \" ') for future analysis\n",
    "- kept one line = one verse; a line break structure for prosodic analysis\n",
    "- removed macron and accents\n",
    "- removed book titles\n",
    "- removed line numbers\n",
    "- removed numeral digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man, Muse—tell me about that resourceful man, who wandered\n",
      "far and wide, when he’d sacked Troy’s sacred citadel:\n",
      "many men’s townships he saw, and learned their ways of thinking,\n",
      "many the griefs he suffered at heart on the open sea,\n",
      "battling for his own life and his comrades’ homecoming. Yet\n",
      "5\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "# Step 1: read txt and remove book's headers\n",
    "filepath = \"/Users/debr/odysseys_en/cleaned_txts/Odyssey_Green_Cleaned.txt\"\n",
    "output_filepath = \"/Users/debr/odysseys_en/normalized_txts/Odyssey_Green_Normalized_v1.txt\"\n",
    "\n",
    "# Create book headers pattern\n",
    "book_headers = [f'Book {i}' for i in range(1, 25)]\n",
    "\n",
    "# Read the entire file\n",
    "with open(filepath, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Filter out the book headers\n",
    "new_lines = [line for line in lines if line.strip() not in book_headers]\n",
    "\n",
    "# Print a preview of the processed text\n",
    "text = \"\".join(new_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path A: Controlled normalization\n",
    "A transparent, \"manual,\" normalization using regex.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Normalize the text\n",
    "import re\n",
    "\n",
    "# Removing numeral digits\n",
    "def remove_digits(text):\n",
    "    \"\"\"\n",
    "    Remove all digit characters from the given text.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Removing diacritics, macrons, circumflex, dieresis/umlaut, etc\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalize text by replacing diacritics with their base characters.\n",
    "    \"\"\"\n",
    "    # Dictionary mapping diacritics to their base characters\n",
    "    replacements = {\n",
    "        # Dieresis/umlaut characters\n",
    "        'ä': 'a', 'ë': 'e', 'ï': 'i', 'ö': 'o', 'ü': 'u',\n",
    "        'Ä': 'A', 'Ë': 'E', 'Ï': 'I', 'Ö': 'O', 'Ü': 'U',\n",
    "        \n",
    "        # Circumflex characters\n",
    "        'â': 'a', 'ê': 'e', 'î': 'i', 'ô': 'o', 'û': 'u',\n",
    "        'Â': 'A', 'Ê': 'E', 'Î': 'I', 'Ô': 'O', 'Û': 'U',\n",
    "        \n",
    "        # Macron characters\n",
    "        'ā': 'a', 'ē': 'e', 'ī': 'i', 'ō': 'o', 'ū': 'u',\n",
    "        'Ā': 'A', 'Ē': 'E', 'Ī': 'I', 'Ō': 'O', 'Ū': 'U',\n",
    "        \n",
    "        # Even more diacritics\n",
    "        # Acute\n",
    "        'á': 'a', 'é': 'e', 'í': 'i', 'ó': 'o', 'ú': 'u',\n",
    "        # Grave\n",
    "        'à': 'a', 'è': 'e', 'ì': 'i', 'ò': 'o', 'ù': 'u',\n",
    "    }\n",
    "    \n",
    "    # Replacement time!\n",
    "    for original, replacement in replacements.items():\n",
    "        text = text.replace(original, replacement)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the normalization to the text\n",
    "text = remove_digits(text)\n",
    "text = normalize_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_norm = \"\".join(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original section:\n",
      "\n",
      "360\n",
      "themselves all went to assembly, but would not permit\n",
      "any others to sit with them, either young or old; and next\n",
      "Eupeithēs’ son Antinoös addressed them, saying: “Look here,\n",
      "see how the gods have saved this fellow from harm!\n",
      "Day after day our lookouts perched up on the windy heights,\n",
      "365\n",
      "\n",
      "\n",
      "Normalized section:\n",
      "\n",
      "360\n",
      "themselves all went to assembly, but would not permit\n",
      "any others to sit with them, either young or old; and next\n",
      "Eupeithes’ son Antinoos addressed them, saying: “Look here,\n",
      "see how the gods have saved this fellow from harm!\n",
      "Day after day our lookouts perched up on the windy heights,\n",
      "365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_and_compare_section(text_to_compare, start_phrase, end_phrase):\n",
    "    \"\"\"\n",
    "    Extract a section of text between two phrases and compare before/after normalization.\n",
    "    \"\"\"\n",
    "    # Find the start and end indices\n",
    "    start_index = text_to_compare.find(start_phrase)\n",
    "    if start_index == -1:\n",
    "        return \"Start phrase not found in text\"\n",
    "    \n",
    "    # Add the length of the start phrase to get to the end of it\n",
    "    start_index += len(start_phrase)\n",
    "    \n",
    "    # Find the end phrase starting from after the start phrase\n",
    "    end_index = text_to_compare.find(end_phrase, start_index)\n",
    "    if end_index == -1:\n",
    "        return \"End phrase not found after the start phrase\"\n",
    "    \n",
    "    # Extract the section\n",
    "    section = text_to_compare[start_index:end_index]\n",
    "    \n",
    "    # Normalize the section\n",
    "    normalized_section = normalize_text(section)\n",
    "    \n",
    "    # Create a comparison output\n",
    "    result = \"Original section:\\n\"\n",
    "    result += section\n",
    "    result += \"\\n\\nNormalized section:\\n\"\n",
    "    result += normalized_section\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "text_to_compare = bf_norm\n",
    "\n",
    "# Extract and compare the section\n",
    "comparison = extract_and_compare_section(\n",
    "    text_to_compare,\n",
    "    \"where proud attendants unloaded their gear, while they\",\n",
    "    \"one succeeding another; and when the sun went down\"\n",
    ")\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_filepath), exist_ok=True)\n",
    "\n",
    "# Write to a new file \n",
    "with open(output_filepath, 'w') as file:\n",
    "    file.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odyssey-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
